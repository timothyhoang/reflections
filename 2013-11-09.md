reflections-1
=============

On Tuesday, it was nice that most groups had met up to draw out a pipeline for the project so that we could work
in parallel because we now have a general idea of which groups were working on our group's input and which groups
needed our output so communication between groups was clarified. Aside from this, many groups had compiled information
from Luen's paper and slides to help get everybody on the same page when it came to the main focus of the project,
the error line for the MDA and ETAS models and how we should approach calculating these differences. It was vital that
at this point in the project, we made it clear that data curation was almost complete and that the main focus at this 
point would be analysis, which I had anticipated would take up the bulk of the time to develop an alarm model that could
fit the ETAS error line.

From this point, I think that it is vital that we talk to someone experienced in working with the
ETAS model such as Luen or Stark because going over the R package documentation, I think that some of the math required 
to fully understand how the ETAS model works is beyond the scope of the class. I think to efficiently best the ETAS model,
we must understand it well enough to develop an alarm model that can predict earthquakes more cheaply through an algorithm
to set alarms compared to the ETAS models' usage of the pdf of time occurence of triggered events and the pdf of the 
location of triggered events. Seeing as this does not seem possible, as Aaron has stressed that we should not be focused
on fully understanding the material because we do not have the luxury of time, it seems as if we are approaching an
algorithm for the MDA alarm model that is based on trial and error. In the long run though, this brute force approach might
cost us more time if we want to push a model that is more successful because it would require several iterations of:

1. Refine model
2. Calculate error
3. Graph error line for both MDA and ETAS
4. If error line fit is in an acceptable range (which we need to define) we are done
5. Otherwise, go back to 1.

In this sense, I think that it was a smart decision to have a group that is solely dedicated to understanding both models
so that while the other analysis groups are working on coding their models, this "consulting group" can then check the MDA
model that the MDA analysis group is developing and give suggestions on how to improve the model.

On Thursday, it was a good idea that we met up in our groups to determine how we could move on after we had the pipeline
established from Tuesday. Since the data curation was essentially complete, the data curators were split up so that they
could help other groups, which was a great idea. Since our group had Tristan, who completed most of the data curation, we
split up to help out other groups. Reena and I had joined the # group to help out with visualizing the raw data, which both
of us knew how to access from working with Tristan's code. At this point, we are trying to approach two different types of
visuals:

1. A time series graph for a parameter (Magnitude, Depth)
2. A geographic graph for any region

We are currently deciding on what tools we want to use, R, Python, or D3 and some of our group members, including me are
going to the D3 workshop on Tuesday, though I feel like D3 will take too long to learn in the time that we have left. This
weekend I will be playing around with matplotlib to try to make code that analyzers can easily use to define a region for
their domain, which was talked about on Tuesday where analyzers needed to look at specific fault lines and draw a geometric
shape around that region to subset their data.
